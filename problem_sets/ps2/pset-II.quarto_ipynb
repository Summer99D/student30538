{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"problem set II\"\n",
        "author: \"Summer Negahdar\"\n",
        "date: \"10/19/2024\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: False\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "This submission is my work alone and complies with the 30538 integrity policy.” Add\n",
        "your initials to indicate your agreement: **SN**\n",
        "\n",
        "2. “I have uploaded the names of anyone I worked with on the problem set here” **Genevieve Madigan**\n",
        "(2 point)\n",
        "\n",
        "3. Late coins used this pset: **01** Late coins left after submission: **02**\n"
      ],
      "id": "ccc15b26"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import altair as alt\n",
        "parking_df= pd.read_csv('data/parking_tickets_one_percent.csv')\n",
        "#I am just going to take a brief look at \n",
        "# the heads to see whether I imported the \n",
        "# right thing or not. \n",
        "parking_df.head()"
      ],
      "id": "7ebb91f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section One: Data cleaning\n",
        "### 1.1\n"
      ],
      "id": "ac102793"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def NA_counter(df):\n",
        "    na_counts = pd.DataFrame({\n",
        "        'Column Name': df.columns,\n",
        "        'Number of NAs': df.isna().sum().values\n",
        "    })\n",
        "\n",
        "    return na_counts\n",
        "\n",
        "\n",
        "NA_table = NA_counter(parking_df)\n",
        "print(NA_table.to_string(index=False)) \n",
        "#I removed the index by to_string command"
      ],
      "id": "54d27872",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2\n",
        "\n",
        "#### Zipcode:\n",
        "this might be due to the fact that many car plat numbers are out-of state (which was discussed in the essay) or it might be an error of manually entering the zip codes!\n",
        "\n",
        "#### Hearing Disposition: \n",
        "If the ticket was not contested this field is blank. this also makes sense since \n",
        "\n",
        "#### Notice Level: \n",
        "the cells that have no notice level(NAs) mean there was no notice sent! this means that a huge majority of ticket receivers were not even notified(which is in accordance with the argument propublica is making)\n",
        "\n",
        "\n",
        "\n",
        "### 1.3\n"
      ],
      "id": "a7640988"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##I could not understand what this question is asking and Genevieve helped me here!\n",
        "# I am going to find all rows whose in \"violation desc\" cell I can \n",
        "# find the word \"sticker\"\n",
        "city_sticker_violations = parking_df[parking_df['violation_description'\n",
        "].str.contains('city sticker', \n",
        "case=False, na=False)]\n",
        "print(city_sticker_violations[\n",
        "    'violation_code'].unique())\n",
        "## so these are the one that involve \"sticker\" let's see what they each are:"
      ],
      "id": "8aa17689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parking_df['issue_date'] = pd.to_datetime(\n",
        "    parking_df['issue_date'\n",
        "    ], format='mixed', \n",
        "    errors='coerce')\n",
        "\n",
        "city_sticker_violations = parking_df[parking_df['violation_description'\n",
        "].str.contains(\n",
        "    'city sticker', case=False, na=False)]\n",
        "\n",
        "sorted_city_sticker_violations = city_sticker_violations.sort_values(by='issue_date')\n",
        "\n",
        "unique_city_sticker_codes = sorted_city_sticker_violations[\n",
        "    ['violation_code', 'violation_description',\n",
        " 'issue_date']\n",
        " ].drop_duplicates(subset='violation_code')\n",
        "\n",
        "print(unique_city_sticker_codes)"
      ],
      "id": "8a2e50c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the explanation goes like this: \n",
        "for 0964125 and 0976170 there is no weight of vehicle involved(these are the old ones)\n",
        "for 0964125B and 0964125C which are new ones, there is a factor of weight. and 0964125D is for those who have a sticker but they display it improparly. (I am going to eliminate these ones form not having sticker violation!)\n",
        "\n",
        "### 1.4\n"
      ],
      "id": "5a4aadf6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#these will be the codes I will be checking that are less than 16k lbs, \n",
        "# and only include missing or improper (not improper solely)\n",
        "violation_codes_light = ['0964125', '0976170', '0964125B']\n",
        "\n",
        "# Filter the DataFrame for the specified violation codes\n",
        "sticker_fines = parking_df[parking_df[\n",
        "    'violation_code'].isin(violation_codes_light)]\n",
        "\n",
        "fine_amounts_lev1 = sticker_fines[['violation_code', 'fine_level1_amount']].drop_duplicates()\n",
        "print(fine_amounts_lev1)"
      ],
      "id": "14078ddf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#as we can see here, the fine amounts used to be 120$ in the past but is 200 right now(the article also mentioned these numbers)\n",
        "\n",
        "## Section Two: Revenue increase from “missing city sticker” tickets\n",
        "\n",
        "###2.1\n"
      ],
      "id": "70664b8d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##so I want to create a dummy variable for sticker\n",
        "# violation to make life easier for myself and you!\n",
        "print(violation_codes_light)\n",
        "\n",
        "# Using apply to create the dummy column\n",
        "parking_df['sticker_violation_dummy'] = parking_df[\n",
        "    'violation_code'].apply(\n",
        "    lambda x: 1 if x in \n",
        "    violation_codes_light else 0\n",
        ")\n",
        "\n",
        "print(parking_df[['violation_code', \n",
        "'sticker_violation_dummy']].head(21))\n",
        "\n",
        "##Now I will create three new columns using date column\n",
        "# one for showing day, one for showing month and one for\n",
        "#showing year!\n",
        "parking_df['issue_date'] = pd.to_datetime(parking_df['issue_date'], errors='coerce')\n",
        "\n",
        "parking_df['month'] = parking_df['issue_date'].dt.month\n",
        "parking_df['day'] = parking_df['issue_date'].dt.day\n",
        "parking_df['year'] = parking_df['issue_date'].dt.year\n",
        "print(parking_df[['issue_date', 'month', 'day', 'year']].head(100))\n",
        "sticker_parking_df= parking_df[parking_df['sticker_violation_dummy']== 1]\n",
        "violation_summary = sticker_parking_df.groupby(['year', 'month'])['sticker_violation_dummy'].sum().reset_index()\n",
        "\n",
        "print(violation_summary)"
      ],
      "id": "bbfb9a2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##now I am going to plot it I will have 12 months on the \n",
        "# X axis and then use mark_line to create different years!\n",
        "import altair as alt\n",
        "\n",
        "# Create a line chart for sticker violations over time\n",
        "total_ticket_count_month_year = alt.Chart(violation_summary).mark_line().encode(\n",
        "    x=alt.X('month:O', axis=alt.Axis(title='Month')),\n",
        "    y=alt.Y('sticker_violation_dummy:Q', axis=alt.Axis(\n",
        "        title='Number of Sticker Violations')),\n",
        "    color='year:N',\n",
        "    tooltip=['year', 'month', 'sticker_violation_dummy']\n",
        ").properties(\n",
        "    title='Monthly Sticker Violations by Year'\n",
        ")\n",
        "\n",
        "total_ticket_count_month_year.display()"
      ],
      "id": "b7bc9ed7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2\n",
        "I want to label each quarter so here is what I do:\n"
      ],
      "id": "2e74ae9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# I have to create a mark_rule chart with the months 3,6,9 and 12\n",
        "quarters = [3, 6, 9, 12]  # End of each quarter\n",
        "quarter_lines = alt.Chart(pd.DataFrame({'month': quarters})\n",
        ").mark_rule(color='red', strokeDash= [4,4]).encode(\n",
        "    x='month:O'\n",
        ")\n",
        "\n",
        "##now we put the two charts on top of each other: \n",
        "guided_chart= total_ticket_count_month_year + quarter_lines\n",
        "guided_chart"
      ],
      "id": "96ff0f6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we can extract from the chart that the highest spike usually happens in the months of March, July to September and occasionally november. it is intersting how july has the largest jump in almost all years!\n",
        "Also, I only asked GPT for how to draw a chart with specified vertical lines and then combined that with my original plot!\n",
        "\n",
        "### 2.3\n"
      ],
      "id": "82a9f857"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#I will filter only the year 2011 and find out the sum of veriables\n",
        "#with the sticker dummy column equalling 1\n",
        "sticker_parking_2011 = parking_df[(\n",
        "    parking_df['year'] == 2011) & (parking_df['sticker_violation_dummy'] == 1)\n",
        "    ]['sticker_violation_dummy'].sum()\n",
        "print(sticker_parking_2011)\n",
        "\n",
        "total_revenue_before= sticker_parking_2011 * 120\n",
        "full_rev_before= total_revenue_before * 100/ 1000000\n",
        "# this will give us the total revenue for 100 percent in Million\n",
        "total_revenue_after= sticker_parking_2011* 200\n",
        "full_rev_after= total_revenue_after * 100/1000000\n",
        "#this will give us total revenue after change in Billion\n",
        "revenue_increase= full_rev_after - full_rev_before\n",
        "print(revenue_increase)"
      ],
      "id": "6081ddce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is actually as the predicted so the increase in revenue would be around 15.5 million or 16 million dollars.\n",
        "\n",
        "### 2.4\n"
      ],
      "id": "d5aae55e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#I first want to see what is the payment fraction for 2011\n",
        "issued_tickets_pre = parking_df[parking_df['year'] == 2011]\n",
        "paid_tickets_pre = issued_tickets_pre[issued_tickets_pre['ticket_queue'] == 'Paid']\n",
        "\n",
        "payment_fraction = len(paid_tickets_pre) / len(issued_tickets_pre)\n",
        "print(f\"The fraction of tickets paid in {2011} is: {payment_fraction:.2f}\")\n",
        "\n",
        "#this means that 71% of the 193500 tickets issued were paid! this\n",
        "#will bring us at the revenue below:\n",
        "paid_fraction_rev_2011= 193500 * 0.71*120\n",
        "\n",
        "\n",
        "#now I want to see how the payment fraction has changed after the\n",
        "#new policy\n",
        "issued_tickets_post = parking_df[parking_df['year'] == 2012]\n",
        "paid_tickets_post = issued_tickets_post[issued_tickets_post['ticket_queue'] == 'Paid']\n",
        "\n",
        "payment_fraction = len(paid_tickets_post) / len(issued_tickets_post)\n",
        "print(f\"The fraction of tickets paid in {2012} is: {payment_fraction:.2f}\")\n",
        "\n",
        "#well the fraction of payment has not changed that much but\n",
        "#let's calculate the rvenue:\n",
        "paid_fraction_rev_2012= 193500 *0.7 *200\n",
        "\n",
        "total_revenue_paid= (paid_fraction_rev_2012 - paid_fraction_rev_2011) / 1000000\n",
        "print(total_revenue_paid)\n",
        "#so the actual revenue (supposing the number of tickets issued is \n",
        "#the same) will be 10 M$ not 16!"
      ],
      "id": "1d28a04e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5\n"
      ],
      "id": "283951e5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#first, I want to create a paid dummy variable as well!\n",
        "sticker_parking_df['paid_dummy'] = sticker_parking_df['ticket_queue'].apply(\n",
        "    lambda x: 1 if x == 'Paid' else 0\n",
        ")\n",
        "#now I calculate the repayment rate using our two dummies:\n",
        "filtered_df = sticker_parking_df[sticker_parking_df['sticker_violation_dummy'] == 1]\n",
        "repayment_rates = filtered_df.groupby('year')['paid_dummy'].mean().reset_index()\n",
        "repayment_rates.rename(columns={'paid_dummy': 'repayment_rate'}, inplace=True)\n",
        "print(repayment_rates)"
      ],
      "id": "ad8d44b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#now I will plot this\n",
        "payment_rate_trend = alt.Chart(repayment_rates).mark_line(point=True).encode(\n",
        "    x=alt.X('year:O', axis=alt.Axis(title='Year')),\n",
        "    y=alt.Y('repayment_rate:Q', axis=alt.Axis(title='Repayment Rate', format='.0%'))\n",
        ").properties(\n",
        "    title='Annual Repayment Rates for \"Missing City Sticker\" Tickets',\n",
        "    width=600,\n",
        "    height=300\n",
        ")\n",
        "#and now I draw another plot for the cutoff line\n",
        "policy_cutoff = alt.Chart(pd.DataFrame({'year': [2012]})).mark_rule(color='red', strokeWidth=2, strokeDash= [4,4]).encode(\n",
        "    x='year:O'\n",
        ")\n",
        "\n",
        "dif_in_dif= payment_rate_trend + policy_cutoff\n",
        "dif_in_dif"
      ],
      "id": "bb459d3e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So what we can see here is RDD where the payment rate drops upon the introduction of the new policy. since we have a continuous line, we can say that the decrease in payment rate is uniquely as a resault of the introduction of the new policy. the article is also talking about the same issue where with the increase of fine for not having a sticker the percentage of people who can pay it off drops, leaving lower income families in more debt!\n",
        "\n",
        "### 2.6\n"
      ],
      "id": "1b01a7c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#I am oging to find the three most repeated violation_code\n",
        "counts = parking_df['violation_code'].value_counts()\n",
        "top_three = counts.nlargest(3)\n",
        "print(top_three)\n",
        "\n",
        "top_three_viol= ['0976160F','0964040B' ,'0964090E']\n",
        "top3_viol= parking_df[parking_df['violation_code'].isin(top_three_viol)][['violation_code', 'violation_description']]\n",
        "print(top3_viol['violation_description'].unique())\n",
        "#these three are the highest committed street crimes: \n",
        "##residential permit parking\n",
        "##expired plates or temp registration\n",
        "##street cleaning!\n",
        "\n",
        "#now I will group by violation type and calculate the repayment rate\n",
        "repayment_rates_by_type = filtered_df.groupby('violation_code')['paid_dummy'].mean().reset_index()\n",
        "repayment_rates_by_type.rename(columns={'paid_dummy': 'repayment_rate'}, inplace=True)\n",
        "three_highest_payment = repayment_rates_by_type.nlargest(3, 'repayment_rate')\n",
        "print(three_highest_payment)\n",
        "three_highest_paid_viol_code= ['0976170', '0964125','0964125B']\n",
        "top3_paid_viol= parking_df[parking_df['violation_code'].isin(three_highest_paid_viol_code)][['violation_code', 'violation_description']]\n",
        "print(top3_paid_viol['violation_description'].unique())"
      ],
      "id": "53c33812",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "so looking at the three highest paid violations I can see where the decision to raise the sticker ticket comes from as they are all sticker-related. \n"
      ],
      "id": "58b5f51c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure 'issue_date' is parsed as datetime\n",
        "parking_df['issue_date'] = pd.to_datetime(parking_df['issue_date'], errors='coerce')\n",
        "\n",
        "# Group by 'violation_code' and 'ticket_queue', counting occurrences\n",
        "viol_rating = parking_df.groupby([\"violation_description\", \"ticket_queue\"])[\"Unnamed: 0\"].count().reset_index()\n",
        "\n",
        "# Rename the count column for clarity\n",
        "viol_rating = viol_rating.rename(columns={\"Unnamed: 0\": \"violation_count\"})\n",
        "\n",
        "# Pivot the table to have 'ticket_queue' values as columns\n",
        "viol_rating = viol_rating.pivot(\n",
        "    index='violation_description',\n",
        "    columns='ticket_queue',\n",
        "    values='violation_count'\n",
        ").reset_index()\n",
        "\n",
        "# Fill NaN values with 0\n",
        "viol_rating = viol_rating.fillna(0)\n",
        "\n",
        "# Calculating the total number of tickets across all statuses\n",
        "viol_rating[\"total_ticket\"] = viol_rating[\n",
        "    [\"Bankruptcy\", \"Court\", \"Define\", \"Dismissed\", \"Hearing Req\", \"Notice\", \"Paid\"]\n",
        "].sum(axis=1)\n",
        "viol_rating[\"repayment_rate\"] = viol_rating[\"Paid\"] / viol_rating[\"total_ticket\"]\n",
        "\n",
        "viol_rating['repayment_rate'] = viol_rating['repayment_rate'].fillna(0)\n",
        "print(viol_rating.head(5))\n",
        "top_ten_violations = viol_rating.nlargest(10, 'total_ticket')\n",
        "\n",
        "# Bar plot for total tickets\n",
        "ticket_plot = alt.Chart(top_ten_violations).mark_bar(\n",
        "    color='green', opacity=1).encode(\n",
        "    x=alt.X('violation_description:N', sort=alt.EncodingSortField(field='total_ticket', order='descending')),\n",
        "    y=alt.Y('total_ticket:Q', axis=alt.Axis(title='Total Tickets'))\n",
        ").properties(\n",
        "    width=600, height=400\n",
        ")\n",
        "\n",
        "# Bar plot for paid tickets\n",
        "paid_plot = alt.Chart(top_ten_violations).mark_bar(\n",
        "    color='orange', opacity=0.8).encode(\n",
        "    x=alt.X('violation_description:N', sort=alt.EncodingSortField(field='total_ticket', order='descending')),\n",
        "    y=alt.Y('Paid:Q', axis=alt.Axis(title='Paid Tickets'))\n",
        ")\n",
        "comparison_chart = ticket_plot + paid_plot\n",
        "\n",
        "comparison_chart"
      ],
      "id": "2503b71e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "following a conversation I had with a friend, I realized we have got two different things for this question and thus I tried it myself as well. when looking at this, we can conclude that \"expired or temporary plate\" has the highest number of tickets while the payment rate is also relatively higher.(I think the city officials did it my way and therefore thought of charging more for sticker biolations!)\n",
        "\n",
        "\n",
        "## Section Three: Headlines and sub-message\n",
        "\n",
        "### 3.1\n"
      ],
      "id": "b6513f4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#I had created paid dummy for sticker partking, \n",
        "#now I am going to do it for the whole df\n",
        "import pandas as pd\n",
        "\n",
        "# Create the 'paid_dummy' column: 1 if 'PAID', else 0\n",
        "parking_df['paid_dummy'] = parking_df['ticket_queue'].apply(lambda x: 1 if x == 'Paid' else 0)\n",
        "\n",
        "# Group by 'violation_description' to calculate metrics\n",
        "violation_summary = parking_df.groupby('violation_description').agg(\n",
        "    paid_fraction=('paid_dummy', 'mean'),  # Fraction of paid tickets\n",
        "    avg_fine=('fine_level1_amount', 'mean'),  # Average fine (level 1)\n",
        "    total_tickets=('violation_code', 'count')  # Total tickets issued\n",
        ").reset_index()\n",
        "# Sort by 'total_tickets' in descending order\n",
        "violation_summary = violation_summary.sort_values(by='total_tickets', ascending=False)\n",
        "\n",
        "# Display the top 6 most common violation descriptions\n",
        "print(violation_summary.head(6))"
      ],
      "id": "c4777d82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###3.2\n"
      ],
      "id": "8cfa9f52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#first I will subset a df with at least 100 tickets:\n",
        "import altair as alt\n",
        "\n",
        "# Subset the DataFrame for violation types with at least 100 tickets\n",
        "subset_df = violation_summary[violation_summary['total_tickets'] >= 100]\n",
        "##I have to remove the outlier, I plotted the \n",
        "# scatterplot and then saw the outlier, I can subset my \n",
        "# df for all fines less than 400 and be safe, but I \n",
        "# asked GPT for a general way to do it without \n",
        "# running a plot once\n",
        "subset_df = subset_df[subset_df['avg_fine'] < subset_df['avg_fine'].quantile(0.99)]\n",
        "##it got rid of all fines that are above \n",
        "# the 0.99 quartile\n",
        "scatter_plot = alt.Chart(subset_df).mark_point(color='green').encode(\n",
        "    x=alt.X('avg_fine:Q', title=\"Average Fine Amount (USD)\"),\n",
        "    y=alt.Y('paid_fraction:Q', title=\"Repayment Rate\"),\n",
        "    tooltip=['violation_description', 'total_tickets', 'avg_fine', 'paid_fraction']\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title=\"Relationship Between Fine Amount and Repayment Rate\"\n",
        ")\n",
        "scatter_plot"
      ],
      "id": "21694a13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### headline: \n",
        "the highest payment rate is for fines less than 80$\n",
        "\n",
        "#### submessage: \n",
        "the repayment rate has no solid patterns as fine amount increases!\n"
      ],
      "id": "e4a58b9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##now a box plot!\n",
        "box_plot = alt.Chart(subset_df).mark_boxplot(color='green').encode(\n",
        "    x=alt.X('avg_fine:Q', title=\"Average Fine Amount (USD)\"),\n",
        "    y=alt.Y('paid_fraction:Q', title=\"Repayment Rate\"),\n",
        "    tooltip=['violation_description', 'total_tickets', 'avg_fine', 'paid_fraction']\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title=\"Relationship Between Fine Amount and Repayment Rate\"\n",
        ")\n",
        "box_plot"
      ],
      "id": "86d030ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### headline: \n",
        "the fines around 75 USD vary a lot in their payment rate(people react very differently to this amount)\n",
        "\n",
        "#### submessage: \n",
        "by using the box plot we can see how variant the payment rate reacts to fine amount. for examply for higher fine rates(around 200) there isn't much divergence in payment rate and it stays pretty ocnstant (more predictable)\n"
      ],
      "id": "d20968af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "##and finally a line plot\n",
        "line_plot = alt.Chart(subset_df).mark_line(color='green').encode(\n",
        "    x=alt.X('avg_fine:Q', title=\"Average Fine Amount (USD)\"),\n",
        "    y=alt.Y('paid_fraction:Q', title=\"Repayment Rate\"),\n",
        "    tooltip=['violation_description', 'total_tickets', 'avg_fine', 'paid_fraction']\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=200,\n",
        "    title=\"Relationship Between Fine Amount and Repayment Rate\"\n",
        ")\n",
        "line_plot"
      ],
      "id": "d61f4397",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### headline: \n",
        "people react to 2-digit fines(under 100) jump to three-digit(100 and above) drastically!\n",
        "\n",
        "#### submessage: \n",
        "payment rate is pretty noisy around under 100 fines (people's payment pattern is not predictable)\n",
        "\n",
        "### 3.3\n",
        "\n",
        "since they need to see how people react to change in fine amount, I would take the line plot as it shows the drastic changes. justl ike I mentioned one the first digit of the fine changes (jump from 99 to 101 and 199 to 201) people suddenly react. (from a consumer analysis standpoint the psychological reasoning behind pricing something with a 0.99 is also the same. people suddenly react negativly to raise in price if the first digit changes! )\n",
        "\n",
        "\n",
        "## Section Four: Understanding the structure of the data and summarizing it\n",
        "\n",
        "4.1\n"
      ],
      "id": "839cb17f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(parking_df.dtypes)\n",
        "#I wanted to make sure fine amount cols are \n",
        "# numeric which they are!\n",
        "\n",
        "#Now I am going to create a new column to see the ratio between first and second round of fines, and I am using subset_df since it already ocntains those with more\n",
        "#than 100 citations\n",
        "subset_df.columns = subset_df.columns.str.strip()\n",
        "subset_df['fine_ratio']= subset_df['fine_level2_amount'] / subset_df['fine_level1_amount']\n",
        "#Now I will see if there are any rows where \n",
        "# fine ratio !=2\n",
        "\n",
        "non_double= subset_df[subset_df['fine_ratio'] !=2]"
      ],
      "id": "3987a014",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}